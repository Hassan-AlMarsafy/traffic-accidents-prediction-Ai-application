{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install requests"
      ],
      "metadata": {
        "id": "fqqyyWDvmSb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"US_Accidents_March23.csv\")\n",
        "\n",
        "# Prune to 40,000 samples (random or top rows)\n",
        "df = df.dropna(subset=[\"Start_Lat\", \"Start_Lng\", \"Start_Time\"])\n",
        "df = df.sample(40000, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "5Vd9NBp0mSeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Start_Time to datetime and extract date\n",
        "df['Start_Time'] = pd.to_datetime(df['Start_Time'], format='mixed', errors='coerce')\n",
        "df = df.dropna(subset=[\"Start_Time\"])  # Drop any rows with invalid time format\n",
        "df['Date'] = df['Start_Time'].dt.date\n",
        "\n",
        "# Keep relevant columns only for weather lookup\n",
        "df_small = df[['ID', 'Start_Lat', 'Start_Lng', 'Date']].copy()"
      ],
      "metadata": {
        "id": "vvT8kfdtmShR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "def get_weather(lat, lon, date):\n",
        "    url = (\n",
        "        f\"https://archive-api.open-meteo.com/v1/archive?\"\n",
        "        f\"latitude={lat}&longitude={lon}\"\n",
        "        f\"&start_date={date}&end_date={date}\"\n",
        "        f\"&daily=temperature_2m_max,temperature_2m_min,precipitation_sum,cloud_cover_mean\"\n",
        "        f\"&timezone=UTC\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url)\n",
        "        data = r.json()\n",
        "        temp_max = data['daily']['temperature_2m_max'][0]\n",
        "        temp_min = data['daily']['temperature_2m_min'][0]\n",
        "        rain = data['daily']['precipitation_sum'][0]\n",
        "        cloud_cover = data['daily']['cloud_cover_mean'][0]\n",
        "        avg_temp = (temp_max + temp_min) / 2.0\n",
        "        return avg_temp, rain, cloud_cover\n",
        "    except:\n",
        "        return None, None, None"
      ],
      "metadata": {
        "id": "pKbhW8cvmSj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "weather_cache = {}\n",
        "weather_data = []\n",
        "\n",
        "for i, row in df_small.iterrows():\n",
        "    lat = round(row['Start_Lat'], 2)\n",
        "    lon = round(row['Start_Lng'], 2)\n",
        "    date = row['Date']\n",
        "    key = (lat, lon, date)\n",
        "\n",
        "    if key in weather_cache:\n",
        "        temp, rain, cloud = weather_cache[key]\n",
        "    else:\n",
        "        temp, rain, cloud = get_weather(lat, lon, date)\n",
        "        weather_cache[key] = (temp, rain, cloud)\n",
        "        time.sleep(1)\n",
        "\n",
        "    weather_data.append((temp, rain, cloud))\n"
      ],
      "metadata": {
        "id": "SQ92gI4tmSma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add weather columns to original pruned DataFrame\n",
        "df_small[['Temperature', 'Rain', 'Cloud_Cover']] = pd.DataFrame(weather_data, index=df_small.index)\n",
        "\n",
        "# Join back with original 40k dataset\n",
        "df_final = pd.merge(df, df_small[['ID', 'Temperature', 'Rain', 'Cloud_Cover']], on='ID')\n",
        "\n",
        "# Save to CSV\n",
        "df_final.to_csv(\"us_accidents_40k_with_weather.csv\", index=False)"
      ],
      "metadata": {
        "id": "z7ggNZrimSpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_PzxhdELmSrZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}